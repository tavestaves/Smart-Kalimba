<!DOCTYPE html>
<html>
<body>
<h2>Live Stream</h2>
<div style="display:flex; gap:12px; align-items:flex-start;">
    <div>
        <button id="btnConnect">Connect</button>
        <button id="btnDisconnect" disabled>Disconnect</button>
        <button id="btnPause" disabled>Pause</button>
        <button id="btnPlay" disabled>Play Recording</button>
        <button id="btnStop" disabled>Stop Playback</button>
        <button id="btnClear" disabled>Clear Recording</button>
        <button id="btnDownload" disabled>Download WAV</button>
        <div style="margin-top:8px; font-size:13px">WebSocket: <span id="wsStatus">DISCONNECTED</span></div>
    </div>
    <canvas id="wave" width="800" height="150" style="border:1px solid #ccc; display:block; margin-bottom:8px"></canvas>
    <div style="width:200px; font-family:sans-serif;">
        <h4>Metrics</h4>
        <div>Queued samples: <span id="queued">0</span></div>
        <div>RMS: <span id="rms">0</span></div>
        <div>Peak: <span id="peak">0</span></div>
        <div>Freq (est): <span id="freq">-</span> Hz</div>
        <div style="margin-top:8px; font-size:12px; color:#666">Recorded samples retained for download</div>
    </div>
</div>
<script>
// WebSocket audio streamer + waveform visualizer
const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
const sourceSampleRate = 8000; // matches ESP sender
let ws = null;
let wsUrl = "ws://192.168.8.107:81/";

// binary type will be set on connect

// simple FIFO queue of float samples (range -1..1)
let sampleQueue = [];
let totalQueued = 0;
// recordedSamples keeps all received samples (for later download)
let recordedSamples = [];

// Jitter buffer parameters
const prefillMs = 120; // wait this many ms of audio before starting playback
const prefillSamples = Math.floor(sourceSampleRate * (prefillMs / 1000));

// resampling state
let readPos = 0.0; // fractional index into the sampleQueue
const resampleStep = sourceSampleRate / audioCtx.sampleRate;
let playing = false;
let paused = false;

// Visualization
const canvas = document.getElementById('wave');
const ctx = canvas.getContext('2d');
const canvasW = canvas.width;
const canvasH = canvas.height;
let lastDrawTime = 0;

function handleMessageData(msg) {
    const arr = new Uint8Array(msg);
    const n = Math.floor(arr.length / 2);
    // Convert to float samples -1..1 (12-bit unsigned centered at 2048)
    for (let i = 0; i < n; i++) {
        const hi = arr[2*i];
        const lo = arr[2*i + 1];
        const value = ((hi << 8) | lo) & 0x0FFF; // mask 12-bit just in case
        const f = (value - 2048) / 2048; // -1..+1
        sampleQueue.push(f);
        recordedSamples.push(f);
    }
    totalQueued += n;
    updateQueuedLabel();
    // enable recording controls once we have data
    if (recordedSamples.length > 0) {
        document.getElementById('btnDownload').disabled = false;
        document.getElementById('btnPlay').disabled = false;
        document.getElementById('btnClear').disabled = false;
    }
    // start playback once we've buffered enough
    if (!playing && !paused && totalQueued >= prefillSamples) {
        playing = true;
        readPos = 0.0;
    }
}

function updateQueuedLabel() {
    document.getElementById('queued').textContent = totalQueued;
}

// ScriptProcessor for streaming audio (widely supported)
const scriptNode = audioCtx.createScriptProcessor(1024, 0, 1);
scriptNode.connect(audioCtx.destination);

scriptNode.onaudioprocess = (audioEvent) => {
    const out = audioEvent.outputBuffer.getChannelData(0);
    const outLen = out.length;

    if (!playing) {
        // output silence until buffer warmed up
        for (let i = 0; i < outLen; i++) out[i] = 0;
        return;
    }

    const step = resampleStep;
    for (let i = 0; i < outLen; i++) {
        const idx = Math.floor(readPos);
        const frac = readPos - idx;
        const s0 = (idx < sampleQueue.length) ? sampleQueue[idx] : 0;
        const s1 = (idx + 1 < sampleQueue.length) ? sampleQueue[idx + 1] : 0;
        out[i] = s0 * (1 - frac) + s1 * frac; // linear interpolation
        readPos += step;
    }

    // Remove consumed samples from front of queue to keep memory low
    const consumed = Math.floor(readPos);
    if (consumed > 0) {
        // drop consumed samples
        sampleQueue.splice(0, consumed);
        totalQueued -= consumed;
        readPos -= consumed;
    }

    // underrun handling
    if (totalQueued <= 0) {
        playing = false; // stop until buffer refills
    }
};

// metrics computation (RMS, peak, zero-cross freq estimate)
function computeMetrics() {
    const win = 1024; // samples window for metrics
    const avail = Math.min(win, sampleQueue.length);
    if (avail === 0) {
        document.getElementById('rms').textContent = '0';
        document.getElementById('peak').textContent = '0';
        document.getElementById('freq').textContent = '-';
        return;
    }
    let sum = 0;
    let peak = 0;
    let crossings = 0;
    let prev = sampleQueue[sampleQueue.length - avail];
    for (let i = 0; i < avail; i++) {
        const v = sampleQueue[sampleQueue.length - avail + i];
        sum += v*v;
        peak = Math.max(peak, Math.abs(v));
        if ((v >= 0 && prev < 0) || (v < 0 && prev >= 0)) crossings++;
        prev = v;
    }
    const rms = Math.sqrt(sum / avail);
    const durationSec = avail / sourceSampleRate;
    const freqEst = (crossings / 2) / durationSec; // rough pitch estimate
    document.getElementById('rms').textContent = rms.toFixed(3);
    document.getElementById('peak').textContent = peak.toFixed(3);
    document.getElementById('freq').textContent = isFinite(freqEst) ? Math.round(freqEst) : '-';
}

setInterval(() => {
    updateQueuedLabel();
    computeMetrics();
}, 200);

// Visualizer: draw a rolling waveform from the queued samples
function drawWave() {
    requestAnimationFrame(drawWave);
    const now = performance.now();
    if (now - lastDrawTime < 30) return; // ~30 fps
    lastDrawTime = now;

    ctx.fillStyle = '#fff';
    ctx.fillRect(0, 0, canvasW, canvasH);

    ctx.lineWidth = 1.5;
    ctx.strokeStyle = '#0077cc';
    ctx.beginPath();

    const samplesToShow = canvasW; // one pixel per sample (downsample if needed)
    const available = sampleQueue.length;
    // build a view of the most recent samples (or silence if not enough)
    const view = new Float32Array(samplesToShow);
    if (available >= samplesToShow) {
        // copy last samplesToShow
        for (let i = 0; i < samplesToShow; i++) view[i] = sampleQueue[Math.max(0, available - samplesToShow + i)];
    } else {
        // pad with silence at the left
        const pad = samplesToShow - available;
        for (let i = 0; i < pad; i++) view[i] = 0;
        for (let i = 0; i < available; i++) view[pad + i] = sampleQueue[i];
    }

    for (let x = 0; x < canvasW; x++) {
        const v = view[x];
        const y = (1 - (v * 0.5 + 0.5)) * canvasH; // map -1..1 to canvas
        if (x === 0) ctx.moveTo(x, y);
        else ctx.lineTo(x, y);
    }
    ctx.stroke();

    // draw status text
    ctx.fillStyle = '#000';
    ctx.font = '12px sans-serif';
    const status = playing ? 'PLAYING' : 'BUFFERING';
    ctx.fillText(`${status}  queued:${totalQueued} samples`, 8, 14);
}

// start visualizer loop
drawWave();
</script>
<script>
// Control wiring: connect/disconnect/pause/download
const btnConnect = document.getElementById('btnConnect');
const btnDisconnect = document.getElementById('btnDisconnect');
const btnPause = document.getElementById('btnPause');
const btnDownload = document.getElementById('btnDownload');
const wsStatus = document.getElementById('wsStatus');

function connectWs() {
    if (ws) return;
    ws = new WebSocket(wsUrl);
    ws.binaryType = 'arraybuffer';
    ws.onopen = () => {
        wsStatus.textContent = 'CONNECTED';
        btnConnect.disabled = true;
        btnDisconnect.disabled = false;
        btnPause.disabled = false;
        btnDownload.disabled = false;
        // resume audio context on user action
        if (audioCtx.state === 'suspended') audioCtx.resume();
    };
    ws.onmessage = (e) => handleMessageData(e.data);
    ws.onclose = () => {
        wsStatus.textContent = 'DISCONNECTED';
        ws = null;
        btnConnect.disabled = false;
        btnDisconnect.disabled = true;
    };
    ws.onerror = (e) => {
        console.error('WS error', e);
    };
}

function disconnectWs() {
    if (!ws) return;
    ws.close();
    ws = null;
    wsStatus.textContent = 'DISCONNECTED';
    btnConnect.disabled = false;
    btnDisconnect.disabled = true;
}

btnConnect.addEventListener('click', () => connectWs());
btnDisconnect.addEventListener('click', () => disconnectWs());

btnPause.addEventListener('click', () => {
    paused = !paused;
    if (paused) {
        btnPause.textContent = 'Resume';
        playing = false;
    } else {
        btnPause.textContent = 'Pause';
        if (totalQueued >= prefillSamples) playing = true;
    }
});

// Download recordedSamples as 16-bit WAV at sourceSampleRate
function downloadWav() {
    if (!recordedSamples.length) return;
    const sampleRate = sourceSampleRate;
    const numChannels = 1;
    const bitsPerSample = 16;
    const blockAlign = numChannels * bitsPerSample/8;
    const byteRate = sampleRate * blockAlign;
    const dataSize = recordedSamples.length * blockAlign;
    const buffer = new ArrayBuffer(44 + dataSize);
    const view = new DataView(buffer);

    /* RIFF identifier */ writeString(view, 0, 'RIFF');
    /* file length */ view.setUint32(4, 36 + dataSize, true);
    /* RIFF type */ writeString(view, 8, 'WAVE');
    /* format chunk identifier */ writeString(view, 12, 'fmt ');
    /* format chunk length */ view.setUint32(16, 16, true);
    /* sample format (raw) */ view.setUint16(20, 1, true);
    /* channel count */ view.setUint16(22, numChannels, true);
    /* sample rate */ view.setUint32(24, sampleRate, true);
    /* byte rate (sample rate * block align) */ view.setUint32(28, byteRate, true);
    /* block align (channel count * bytes per sample) */ view.setUint16(32, blockAlign, true);
    /* bits per sample */ view.setUint16(34, bitsPerSample, true);
    /* data chunk identifier */ writeString(view, 36, 'data');
    /* data chunk length */ view.setUint32(40, dataSize, true);

    // Write PCM samples
    let offset = 44;
    for (let i = 0; i < recordedSamples.length; i++, offset += 2) {
        let s = Math.max(-1, Math.min(1, recordedSamples[i]));
        view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
    }

    const blob = new Blob([view], { type: 'audio/wav' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = 'recording.wav';
    document.body.appendChild(a);
    a.click();
    a.remove();
    URL.revokeObjectURL(url);
}

function writeString(view, offset, string) {
    for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
    }
}

btnDownload.addEventListener('click', downloadWav);

// Playback controls
let playSource = null;
function playRecording() {
    if (!recordedSamples.length || playSource) return;
    // Create AudioBuffer at source sample rate and play
    const buffer = audioCtx.createBuffer(1, recordedSamples.length, sourceSampleRate);
    const ch = buffer.getChannelData(0);
    for (let i = 0; i < recordedSamples.length; i++) ch[i] = recordedSamples[i];

    playSource = audioCtx.createBufferSource();
    playSource.buffer = buffer;
    playSource.connect(audioCtx.destination);
    playSource.onended = () => {
        playSource = null;
        document.getElementById('btnStop').disabled = true;
        document.getElementById('btnPlay').disabled = false;
    };
    // resume context if suspended
    if (audioCtx.state === 'suspended') audioCtx.resume();
    playSource.start();
    document.getElementById('btnStop').disabled = false;
    document.getElementById('btnPlay').disabled = true;
}

function stopPlayback() {
    if (playSource) {
        try { playSource.stop(); } catch (e) {}
        playSource = null;
    }
    document.getElementById('btnStop').disabled = true;
    document.getElementById('btnPlay').disabled = recordedSamples.length === 0;
}

function clearRecording() {
    recordedSamples = [];
    // also clear queued samples and stop playback
    sampleQueue = [];
    totalQueued = 0;
    updateQueuedLabel();
    stopPlayback();
    document.getElementById('btnDownload').disabled = true;
    document.getElementById('btnPlay').disabled = true;
    document.getElementById('btnClear').disabled = true;
}

document.getElementById('btnPlay').addEventListener('click', playRecording);
document.getElementById('btnStop').addEventListener('click', stopPlayback);
document.getElementById('btnClear').addEventListener('click', clearRecording);
</script>
</script>
</body>
</html>
